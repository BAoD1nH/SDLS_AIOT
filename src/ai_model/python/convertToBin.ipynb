{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc95ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def convert_image_to_bin(image_path, output_bin_path, target_size=(112, 112)):\n",
    "\ttry:\n",
    "\t\t# 1. Mở và resize ảnh\n",
    "\t\timg = Image.open(image_path).convert(\"RGB\")\n",
    "\t\timg = img.resize(target_size)\n",
    "\n",
    "\t\t# 2. Chuẩn hóa: từ [0, 255] → [-1, 1]\n",
    "\t\timg_array = np.array(img).astype(np.float32)\n",
    "\t\timg_array = img_array / 127.5 - 1.0\n",
    "\n",
    "\t\t# 3. Ghi thành file nhị phân .bin\n",
    "\t\timg_array.flatten().tofile(output_bin_path)\n",
    "\n",
    "\t\tprint(f\"[✓] Đã lưu vào: {output_bin_path}. Shape: {img_array.shape}, dtype: float32\")\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"[✗] Lỗi khi xử lý ảnh: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da09963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Đã lưu vào: input.bin. Shape: (112, 112, 3), dtype: float32\n"
     ]
    }
   ],
   "source": [
    "image_path = \"input.jpg\"\n",
    "output_bin_path = \"input.bin\"\n",
    "\n",
    "convert_image_to_bin(image_path, output_bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a0f5c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not open 'embedding_model.tflite'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m IMG_SIZE = (\u001b[32m96\u001b[39m, \u001b[32m96\u001b[39m)  \u001b[38;5;66;03m# Ví dụ với MobileFaceNet\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load TFLite model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m interpreter = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInterpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m interpreter.allocate_tensors()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Lấy chi tiết input/output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bao Dinh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:464\u001b[39m, in \u001b[36mInterpreter.__init__\u001b[39m\u001b[34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors, experimental_disable_delegate_clustering)\u001b[39m\n\u001b[32m    458\u001b[39m custom_op_registerers_by_name = [\n\u001b[32m    459\u001b[39m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    460\u001b[39m ]\n\u001b[32m    461\u001b[39m custom_op_registerers_by_func = [\n\u001b[32m    462\u001b[39m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    463\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[38;5;28mself\u001b[39m._interpreter = \u001b[43m_interpreter_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateWrapperFromFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_resolver_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperimental_preserve_all_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperimental_disable_delegate_clustering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._interpreter:\n\u001b[32m    473\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mFailed to open \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(model_path))\n",
      "\u001b[31mValueError\u001b[39m: Could not open 'embedding_model.tflite'."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Đường dẫn file\n",
    "IMAGE_PATH = \"label.jpg\"\n",
    "OUTPUT_TXT_PATH = \"label.txt\"\n",
    "MODEL_PATH = \"embedding_model.tflite\"  # Đổi thành .h5 nếu bạn dùng Keras\n",
    "\n",
    "# Kích thước ảnh đầu vào của model (tùy thuộc vào model bạn dùng)\n",
    "IMG_SIZE = (96, 96)  # Ví dụ với MobileFaceNet\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Lấy chi tiết input/output\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load và tiền xử lý ảnh\n",
    "img = Image.open(IMAGE_PATH).convert('RGB')\n",
    "img = img.resize(IMG_SIZE)\n",
    "img_array = np.array(img, dtype=np.float32) / 255.0  # chuẩn hóa [0, 1]\n",
    "img_array = np.expand_dims(img_array, axis=0)  # thêm batch dimension\n",
    "\n",
    "# Gán input cho model\n",
    "interpreter.set_tensor(input_details[0]['index'], img_array)\n",
    "\n",
    "# Chạy mô hình\n",
    "interpreter.invoke()\n",
    "\n",
    "# Lấy embedding\n",
    "embedding = interpreter.get_tensor(output_details[0]['index'])[0]  # shape: (192,)\n",
    "\n",
    "# Lưu vào label.txt\n",
    "with open(OUTPUT_TXT_PATH, 'w') as f:\n",
    "\tfor val in embedding:\n",
    "\t\tf.write(f\"{val:.6f} \")\n",
    "\n",
    "print(f\"Embedding vector saved to {OUTPUT_TXT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
